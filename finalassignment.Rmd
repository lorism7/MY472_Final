---
title: "MY472 Final Assignment"
output: html_document
date: "2024-01-10"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE)
```

My public repository for this assignment can be found [here](https://github.com/lorism7/MY472_Final.git).

### Introduction

This analysis seeks to identify potential biases in the UK's police stop and search practices, particularly regarding officer-perceived ethnicity. Our methodology involves data sourcing and preprocessing from the UK Police database and the Office for National Statistics, focusing on demographic and geographic aspects. We place significant emphasis on calculating and analyzing the proportion of false stop and searches by ethnicity and region, as this metric could reflect the accuracy and justification of police actions, indicating potential discriminatory biases if certain ethnic groups are disproportionately subject to unjustified searches. Through both visualization and statistical analysis, our approach aims to provide a comprehensive understanding of these law enforcement practices and their implications for fairness and public trust.

### Data

#### UK Police Data API


```{r getting data from the uk police api}
library(httr)
library(jsonlite)
library(lubridate)

# forces <- c("avon-and-somerset", "bedfordshire", "btp", "cambridgeshire", "cheshire", 
#            "city-of-london", "cleveland", "cumbria", "derbyshire", "devon-and-cornwall", 
 #           "dorset", "durham", "dyfed-powys", "essex", "gloucestershire", "gmp", "gwent", 
  #          "hampshire", "hertfordshire", "humberside", "kent", "lancashire", "leicestershire", 
   #         "lincolnshire", "merseyside", "metropolitan", "norfolk", "north-wales", 
    #        "north-yorkshire", "northamptonshire", "northumbria", "nottinghamshire", "psni", 
     #       "south-wales", "south-yorkshire", "staffordshire", "suffolk", "surrey", 
     #       "sussex", "thames-valley", "warwickshire", "west-mercia", "west-midlands", 
      #      "west-yorkshire", "wiltshire")

# date_seq <- c("2021-01", "2021-02", "2021-03", "2021-04", "2021-05",
#                "2021-06", "2021-07", "2021-08", "2021-09", "2021-10", "2021-11", "2021-12")


# Define the columns to keep
# columns_to_keep <- c("age_range", "gender", "datetime", "officer_defined_ethnicity", 
               #      "type", "outcome_linked_to_object_of_search", "location.latitude", 
               #      "location.longitude", "location.street.id", "location.street.name", "force")


#all_data <- list()

#for (force in forces) {
  #  force_data <- list()

    #for (date in date_seq) {
        #url <- paste0("https://data.police.uk/api/stops-force?force=", force, "&date=", date)
        #response <- GET(url)
       # if (status_code(response) == 200) {
     #       data <- fromJSON(content(response, "text", encoding = "UTF-8"), flatten = TRUE)
       #     if (is.data.frame(data) && nrow(data) > 0) {
      #          data$force <- force  # Add the force name here

                # Standardize columns
        #        for (col in columns_to_keep) {
         #           if (!col %in% names(data)) {
          #              data[[col]] <- NA  # Add missing columns as NA
           #         }
            #    }
             #   data <- data[, columns_to_keep]  # Keep only the desired columns

              #  force_data[[date]] <- data
          #  } else {
           #     warning("No data or incorrect format for ", force, " for date ", date)
            #}
      #  } else {
     #       warning("Failed to retrieve data for ", force, " for date ", date)
      #  }
  #  }

    # Combine data frames for this force
   # if (length(force_data) > 0) {
#        all_data[[force]] <- do.call(rbind, force_data)
 #   }
#}

# Combine all the data into one data frame
#combined_data <- do.call(rbind, all_data)

# Handle Missing Values
#combined_data <- na.omit(combined_data)

# Convert 'datetime' to Date format
#combined_data$datetime <- as.Date(combined_data$datetime, format="%Y-%m-%dT%H:%M:%S") 

#head(combined_data)

# Save the combined data to a CSV file
#write.csv(combined_data, "police_stops_data.csv", row.names = FALSE)

# Read the data from the saved file
combined_data <- read.csv("police_stops_data.csv")

```

```{r percentage of non-white}
# Load necessary libraries
library(sf)
library(dplyr)
library(ggplot2)
library(readr)
library(viridis)


# Read the shapefile
lad_shapefile <- st_read("Local_Authority_Districts_(May_2021)_UK_BGC/LAD_MAY_2021_UK_BGC.shp", quiet = TRUE)

# Read the CSV data
data <- read_csv2("ethnicity-composition-across-uk.csv")


# sum up all non-white ethnicity percentages.
library(dplyr)


clean_data <- data %>% 
  filter(`Asian, Asian British or Asian Welsh: Bangladesh` != "-", 
                           `Asian, Asian British or Asian Welsh: Chinese` != "-",
                           `Asian, Asian British or Asian Welsh: Indian` != "-",
                           `Asian, Asian British or Asian Welsh: Pakistani`!= "-",
                           `Asian, Asian British or Asian Welsh: Other Asian` != "-",
                           `Black, Black British, Black Welsh, Caribbean or African: African` != "-",
                           `Black, Black British, Black Welsh, Caribbean or African: Caribbean` != "-",
                           `Black, Black British, Black Welsh, Caribbean or African: Other Black` != "-", 
                           `Mixed or Multiple ethnic groups: White and Asian` != "-", 
                           `Mixed or Multiple ethnic groups: White and Black African` != "-", 
                           `Mixed or Multiple ethnic groups: White and Black Caribbean` != "-",
                           `Mixed or Multiple ethnic groups: Other Mixed or Multiple ethnic groups` != "-",
                           `Other ethnic group: Arab` != "-",
                           `Other ethnic group: Any other ethnic group` != "-")

data <- clean_data %>%
  mutate(
    `Asian, Asian British or Asian Welsh: Bangladesh` = as.numeric(gsub(",", ".", `Asian, Asian British or Asian Welsh: Bangladesh`)),
    `Asian, Asian British or Asian Welsh: Chinese` = as.numeric(gsub(",", ".", `Asian, Asian British or Asian Welsh: Chinese`)),
    `Asian, Asian British or Asian Welsh: Indian` = as.numeric(gsub(",", ".", `Asian, Asian British or Asian Welsh: Indian`)),
    `Asian, Asian British or Asian Welsh: Pakistani` = as.numeric(gsub(",", ".", `Asian, Asian British or Asian Welsh: Pakistani`)),
    `Asian, Asian British or Asian Welsh: Other Asian` = as.numeric(gsub(",", ".", `Asian, Asian British or Asian Welsh: Other Asian`)),
    `Black, Black British, Black Welsh, Caribbean or African: African` = as.numeric(gsub(",", ".", `Black, Black British, Black Welsh, Caribbean or African: African`)),
    `Black, Black British, Black Welsh, Caribbean or African: Caribbean` = as.numeric(gsub(",", ".", `Black, Black British, Black Welsh, Caribbean or African: Caribbean`)),
    `Black, Black British, Black Welsh, Caribbean or African: Other Black` = as.numeric(gsub(",", ".", `Black, Black British, Black Welsh, Caribbean or African: Other Black`)),
    `Mixed or Multiple ethnic groups: White and Asian` = as.numeric(gsub(",", ".", `Mixed or Multiple ethnic groups: White and Asian`)),
    `Mixed or Multiple ethnic groups: White and Black African` = as.numeric(gsub(",", ".", `Mixed or Multiple ethnic groups: White and Black African`)),
    `Mixed or Multiple ethnic groups: White and Black Caribbean` = as.numeric(gsub(",", ".", `Mixed or Multiple ethnic groups: White and Black Caribbean`)),
    `Mixed or Multiple ethnic groups: Other Mixed or Multiple ethnic groups` = as.numeric(gsub(",", ".", `Mixed or Multiple ethnic groups: Other Mixed or Multiple ethnic groups`)),
    `Other ethnic group: Arab` = as.numeric(gsub(",", ".", `Other ethnic group: Arab`)),
    `Other ethnic group: Any other ethnic group` = as.numeric(gsub(",", ".", `Other ethnic group: Any other ethnic group`))
  )


data <- data %>%
  rowwise() %>%
  mutate(PercentNonWhite = `Asian, Asian British or Asian Welsh: Bangladesh` +
                           `Asian, Asian British or Asian Welsh: Chinese` +
                           `Asian, Asian British or Asian Welsh: Indian` +
                           `Asian, Asian British or Asian Welsh: Pakistani` +
                           `Asian, Asian British or Asian Welsh: Other Asian` +
                           `Black, Black British, Black Welsh, Caribbean or African: African` +
                           `Black, Black British, Black Welsh, Caribbean or African: Caribbean` +
                           `Black, Black British, Black Welsh, Caribbean or African: Other Black` +
                           `Mixed or Multiple ethnic groups: White and Asian` +
                           `Mixed or Multiple ethnic groups: White and Black African` +
                           `Mixed or Multiple ethnic groups: White and Black Caribbean` +
                           `Mixed or Multiple ethnic groups: Other Mixed or Multiple ethnic groups` +
                           `Other ethnic group: Arab` +
                           `Other ethnic group: Any other ethnic group`) %>%
  ungroup()




# Merge the shapefile and CSV data
map_data <- left_join(lad_shapefile, data, by = c("LAD21CD" = "Area code"))

# Assuming your merged shapefile and data is in 'uk_data'
map1 <- ggplot(data = map_data) +
  geom_sf(aes(fill = PercentNonWhite), color = NA) +  # No border color
  scale_fill_viridis_c(
    option = "C",  # Viridis color option
    direction = 1,  # Sets the direction of the color scale
    name = "Percent Non-White",  # Legend title
    labels = scales::percent_format(scale = 1),  # Format labels as percentages
    na.value = "grey"  # Color for NA values
  ) +
  labs(
    title = "Percentage of Non-White Ethnicities",
    caption = "Source: data.gov.uk"
  ) +
  theme_minimal() +
  theme(
    legend.position = "right",  # Adjust legend position
    plot.title = element_text(size = 14, face = "bold"),  # Title style
    plot.subtitle = element_text(size = 12)  # Subtitle style
  )

```


```{r stop-and-search incidents distribution}
library(sf)
library(dplyr)
library(ggplot2)

# Assuming the shapefiles are in the specified directory
uk_shape <- st_read('ne_10m_admin_0_countries/ne_10m_admin_0_countries.shp', quiet = TRUE)

# Filter for the United Kingdom
uk <- uk_shape %>% 
  filter(ADMIN == "United Kingdom")

combined_data$location.latitude <- as.numeric(as.character(combined_data$location.latitude))
combined_data$location.longitude <- as.numeric(as.character(combined_data$location.longitude))

# Create a simple feature object from your data
stops_sf <- st_as_sf(combined_data, coords = c("location.longitude", "location.latitude"), 
                     crs = st_crs(uk), agr = "constant")


map2 <- ggplot() +
  geom_sf(data = uk) +  # Plot the UK map
  geom_sf(data = stops_sf, color = 'red', size = 0.6, alpha = 0.7) +  # Plot the stop and search data
  theme_minimal() +
  labs(title = "Distribution of Stop and Searches",
    caption = "Source: data.police.uk"
  ) +
  theme(
    plot.title = element_text(size = 14, face = "bold") # Title style
  )

```

```{r map together in a single visualisation}
library(ggplot2)

# Modify map1 to remove axes
map1 <- map1 + 
  coord_sf() +  # Add coordinate system for spatial data+ 
  theme(
    panel.grid.major = element_blank(), 
    panel.grid.minor = element_blank(),
    plot.title = element_text(hjust = 0.5, size = 10),  # Adjust title size
    axis.title = element_blank(),  # Remove axis titles
    axis.text = element_blank(),   # Remove axis text
    axis.ticks = element_blank(),   # Remove axis ticks
    legend.position = "left", # Move legend to bottom
    legend.title = element_text(size = 7),  # Adjust the size of the legend title
    legend.text = element_text(size = 7),    # Adjust the size of the legend text
    legend.key.size = unit(0.75, "lines") # Adjust the size of the legend keys
  )


# Modify map2 to remove axes
map2 <- map2 + 
  coord_sf() +  # Add coordinate system for spatial data+ 
  theme(
    panel.grid.major = element_blank(), 
    panel.grid.minor = element_blank(),
    plot.title = element_text(hjust = 0.5, size = 10),  # Adjust title size
    axis.title = element_blank(),  # Remove axis titles
    axis.text = element_blank(),   # Remove axis text
    axis.ticks = element_blank()   # Remove axis ticks
  )

# Adjust margins of the maps
map1 <- map1 + theme(plot.margin = margin(1, 1, 1, 1, "cm"))
map2 <- map2 + theme(plot.margin = margin(1, 1, 1, 1, "cm"))

# Combine the plots with patchwork
library(patchwork)
combined_map_layout <- map1 + map2 +
  plot_layout(ncol = 2)

# Print the combined plot
print(combined_map_layout)
```


```{r bar chart}
# Load necessary libraries
library(tidyverse)

# Assuming your data is loaded into a dataframe named 'police_stops_data'

# Read the CSV file (adjust the path as needed)
police_stops_data <- read.csv('police_stops_data.csv')

# Creating a new variable for false stop and searches
# A false stop and search is one where the outcome is not linked to the object of search
police_stops_data$false_stop_search <- !police_stops_data$outcome_linked_to_object_of_search

# Calculate the proportion of false stop and searches for each ethnicity
ethnicity_summary <- police_stops_data %>%
  group_by(officer_defined_ethnicity) %>%
  summarise(
    total_searches = n(),
    false_searches = sum(false_stop_search),
    proportion_false_searches = false_searches / total_searches
  )

# Plotting the proportion of false stop and searches by ethnicity
ggplot(ethnicity_summary, aes(x = officer_defined_ethnicity, y = proportion_false_searches, fill = officer_defined_ethnicity)) +
  geom_bar(stat = 'identity') +
  scale_fill_brewer(palette = "Set2") +
  geom_text(aes(label = round(proportion_false_searches, 3)), vjust = -0.5) +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    plot.title = element_text(size = 14, face = "bold"),
    plot.subtitle = element_text(size = 12),
    legend.position = "none"
  ) +
  labs(
    title = 'Proportion of False Stop and Searches by Ethnicity',
    subtitle = 'Comparison across different ethnic groups',
    x = 'Officer-Defined Ethnicity',
    y = 'Proportion of False Searches'
  )

```

```{r adding police force to the analysis}
# Load necessary libraries
library(tidyverse)

# Assuming your data is loaded into a dataframe named 'police_stops_data'

# Read the CSV file (adjust the path as needed)
police_stops_data <- read.csv('police_stops_data.csv')

# Creating a new variable for false stop and searches
police_stops_data$false_stop_search <- !police_stops_data$outcome_linked_to_object_of_search

# Group by region (force) and ethnicity, and calculate proportions
regional_ethnicity_summary <- police_stops_data %>%
  group_by(force, officer_defined_ethnicity) %>%
  summarise(
    total_searches = n(),
    false_searches = sum(false_stop_search),
    proportion_false_searches = false_searches / total_searches
  ) %>%
  ungroup()

ggplot(regional_ethnicity_summary, aes(x = force, y = proportion_false_searches, color = officer_defined_ethnicity, group = officer_defined_ethnicity)) +
  geom_line() +
  geom_point() +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  labs(
    title = 'Trends in False Stop and Searches by Ethnicity Across Regions',
    subtitle = 'Each line represents an ethnicity',
    x = 'Region (Police Force)',
    y = 'Proportion of False Searches',
    color = 'Ethnicity'
  )

```

```{r regression}
# Load necessary libraries
library(dplyr)

# Read your data into a dataframe
# Read the CSV file into a dataframe
data <- read.csv('police_stops_data.csv')


# Define false stop and searches
# Assuming a false stop and search is when 'outcome_linked_to_object_of_search' is FALSE
data$false_stop_search <- !data$outcome_linked_to_object_of_search


# Convert categorical variables to factors
data$force <- as.factor(data$force)
data$officer_defined_ethnicity <- as.factor(data$officer_defined_ethnicity)
data$false_stop_search <- as.factor(data$outcome_linked_to_object_of_search)

# Fit a logistic regression model
logistic_model <- glm(false_stop_search ~ force + officer_defined_ethnicity, data = data, family = 'binomial')

library(broom)

# Assuming your logistic model is named logistic_model
tidied_model <- tidy(logistic_model)

# Selecting important columns
important_results <- tidied_model %>%
  select(term, estimate, std.error, statistic, p.value)

# Viewing the table
print(important_results)


```
The results from your logistic regression model provide a lot of information. Here's how to interpret these results:

Coefficients (Estimate):
Each coefficient in the model represents the log odds of the outcome (a false stop and search) for that category, relative to the reference category, while holding other variables constant.
For example, the coefficient for forcebtp is -2.02768. This suggests that, compared to the reference category (which is the first category of force not shown in the summary), the log odds of a false stop and search are lower in the 'btp' police force.
Statistical Significance (Pr(>|z|)):
The p-values indicate whether the coefficients are statistically significantly different from 0.
A small p-value (typically less than 0.05) suggests that the effect of that predictor on the outcome is significant.
For example, forcebtp has a p-value of less than 2e-16, which is very small, indicating that it is a significant predictor of the outcome.
Overall Model Fit:
The 'Null deviance' and 'Residual deviance' give you a sense of how well the model fits the data. A large drop in deviance indicates a good fit.
The AIC (Akaike Information Criterion) is a measure of the quality of the model; lower values indicate a better model fit.
Interpretation of Key Results:
Many of the force categories have significant coefficients, indicating that there are regional variations in the likelihood of false stop and searches.
The coefficient for officer_defined_ethnicityBlack is significant and negative, suggesting that being classified as Black decreases the log odds of a false stop and search compared to the baseline ethnicity (likely 'Asian' in this case, as it's the first alphabetically).
Some coefficients, such as forceleicestershire and forcenorthumbria, have extremely large estimates and should be interpreted with caution. This could be due to very low or high proportions of false searches in these categories, or it could be an indication of data issues or model overfitting.
Are These Results Meaningful?
The results are meaningful as they indicate significant differences in the likelihood of false stop and searches based on region and ethnicity.
However, interpretation should be cautious. Logistic regression coefficients can be influenced by unmeasured confounding variables and the choice of reference categories.
The model indicates that both region (force) and ethnicity significantly affect the likelihood of a false stop and search, but it's important to consider the broader context, including potential biases in policing practices and demographic differences across regions.
To further understand the implications of these findings, you might want to delve deeper into specific significant predictors or consult with a domain expert.





## Appendix: All code in this assignment

```{r ref.label=knitr::all_labels(), echo=TRUE, eval=FALSE} 
# this chunk generates the complete code appendix. 
# eval=FALSE tells R not to run (``evaluate'') the code here (it was already run before).
```
